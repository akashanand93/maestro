{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import json\n",
    "import torch\n",
    "import argparse\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from model_dev.dataloader import data_provider\n",
    "from model_dev.stock_picker import StockPicker\n",
    "from model_dev.visualize.visualize_single import Visualize, craete_heatmap\n",
    "from model_dev.visualize.scatter_plot import Scatter\n",
    "from model_dev.utills import read_default_args, load_model, get_stock_meta, get_stock_heatmap_matrix\n",
    "\n",
    "# import mse loss from torch\n",
    "from torch.nn import MSELoss\n",
    "# import lregularized mse loss from torch\n",
    "\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from model_dev.expirement import ExpMain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "default_args = read_default_args()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config_file = '../../configs/config_akash.json'\n",
    "data_dir_overrides = [\"/Users/akashanand/repo/data/ltsf/iteration1/data_maestro\",\n",
    "                      \"/Users/akashanand/repo/data/ltsf/iteration2/data_maestro\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_matrices = []\n",
    "for iteration_idx, data_dir_override in enumerate(data_dir_overrides):\n",
    "    config = json.load(open(config_file))\n",
    "    if data_dir_override != \"\":\n",
    "        config['data_dir'] = data_dir_override\n",
    "    data_dir = config['data_dir']\n",
    "    raw_dir = \"{}/{}\".format(data_dir, config['raw_data_dir'])\n",
    "    csv_dir = \"{}/{}\".format(data_dir, config['raw_data_csv'])\n",
    "    ltsf = \"{}/ltsf\".format(data_dir)\n",
    "    print(\"data_dir: {}\".format(data_dir))\n",
    "    target_wise_attention = []\n",
    "    for i in range(397):\n",
    "        args = {\n",
    "        'root_path': ltsf,\n",
    "        'checkpoints': '{}/checkpoints/'.format(data_dir),\n",
    "        'data_path': '03_23.csv',\n",
    "        'seq_len': 120,\n",
    "        'pred_len': 30,\n",
    "        'batch_size': 1,\n",
    "        'learning_rate': 0.025,\n",
    "        'train_only': False,\n",
    "        'train_epochs': 20,\n",
    "        'data_segment': None,\n",
    "        'model': 'nlinear_attention',\n",
    "        'enc_in': 397,\n",
    "        'patience': 5,\n",
    "        'target': i,\n",
    "        'stocks': None\n",
    "        }\n",
    "\n",
    "        for key, value in args.items():\n",
    "            default_args[key] = value\n",
    "\n",
    "        args = argparse.Namespace(**default_args)\n",
    "        setting = 'mod_{}_sl{}_pl{}_ds_{}_tg_{}_ch_{}'.format(args.model, args.seq_len, args.pred_len, args.data_path.split('.')[0], args.target, args.enc_in)\n",
    "        if iteration_idx != 0:\n",
    "            setting = setting + \"_\" + str(iteration_idx + 1)\n",
    "        weights = os.listdir(\"{}/{}\".format(args.checkpoints, setting))\n",
    "        sorted_weights = sorted(weights, key=lambda x: float(x.replace('checkpoint_','').replace('.pth','')), reverse=True)\n",
    "        model = load_model(args)\n",
    "        model.load_state_dict(torch.load(\"{}/{}/{}\".format(args.checkpoints, setting, sorted_weights[-1])))\n",
    "        target_wise_attention.append(model.Attention.weight.cpu().detach().numpy().flatten().tolist())\n",
    "    matrix = np.array(target_wise_attention)\n",
    "    all_matrices.append(matrix)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "\n",
    "# Create a figure and a 1x2 grid of subplots\n",
    "fig, axs = plt.subplots(1, 2, figsize=(10, 5))\n",
    "\n",
    "# Plot heatmap on the first subplot\n",
    "sns.heatmap(all_matrices[0], cmap='RdBu',vmin=-1, vmax=1, ax=axs[0])\n",
    "axs[0].set_title('Heatmap 0')\n",
    "\n",
    "# Plot heatmap on the second subplot\n",
    "sns.heatmap(all_matrices[1], cmap='RdBu',vmin=-1, vmax=1, ax=axs[1])\n",
    "axs[1].set_title('Heatmap 1')\n",
    "\n",
    "# Display the figure with its two subplots\n",
    "plt.tight_layout() # Ensures a bit of spacing between plots\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = get_stock_meta(\"{}/instruments.json\".format(ltsf), \"{}/03_23.csv\".format(ltsf))\n",
    "names = []\n",
    "for k, v in a.items():\n",
    "    names.append(v['name'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "intersection = {}\n",
    "num_intersection1 = {}\n",
    "num_intersection2 = {}\n",
    "threshold = 0.4\n",
    "for i in range(len(all_matrices[0])):\n",
    "    vals1 = [abs(x) for x in all_matrices[0][i]]\n",
    "    vals2 = [abs(x) for x in all_matrices[1][i]]\n",
    "    # Calculate intersection of indexes based on threshold\n",
    "    num_intersection1[names[i]] = len([x for x in vals1 if x > threshold])\n",
    "    num_intersection2[names[i]] = len([x for x in vals2 if x > threshold])\n",
    "    intersection[names[i]] = [names[x] for x in range(len(vals1)) if vals1[x] > threshold and vals2[x] > threshold]\n",
    "# Sort based on number of intersections\n",
    "sorted_intersection = sorted(intersection.items(), key=lambda x: len(x[1]), reverse=True)\n",
    "out = [(x[0], len(x[1])) for x in sorted_intersection]\n",
    "for x in out:\n",
    "    print(x[0], x[1], num_intersection1[x[0]], num_intersection2[x[0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "intersection = {}\n",
    "top_k = 20\n",
    "for i in range(len(all_matrices[0])):\n",
    "    vals1 = [abs(x) for x in all_matrices[0][i]]\n",
    "    vals2 = [abs(x) for x in all_matrices[1][i]]\n",
    "    # Calculate intersection of indexes based on threshold\n",
    "    top_k_indices1 = np.argsort(vals1)[-top_k:]\n",
    "    top_k_indices2 = np.argsort(vals2)[-top_k:]\n",
    "    intersection[names[i]] = list(set([names[x] for x in top_k_indices1]).intersection(set([names[x] for x in top_k_indices2])))\n",
    "# Sort based on number of intersections\n",
    "sorted_intersection = sorted(intersection.items(), key=lambda x: len(x[1]), reverse=True)\n",
    "out = [(x[0], len(x[1])) for x in sorted_intersection]\n",
    "for x in out:\n",
    "    print(x[0], x[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "trading",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
