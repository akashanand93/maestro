{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4088cac8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import torch\n",
    "import argparse\n",
    "from torch import nn\n",
    "from expirement import ExpMain\n",
    "import matplotlib.pyplot as plt\n",
    "from dataloader import data_provider\n",
    "from utills import read_default_args\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "706b9ced",
   "metadata": {},
   "outputs": [],
   "source": [
    "config_file = '../configs/config_shiva.json'\n",
    "config = json.load(open(config_file))\n",
    "data_dir = config['data_dir']\n",
    "raw_dir = \"{}/{}\".format(data_dir, config['raw_data_dir'])\n",
    "csv_dir = \"{}/{}\".format(data_dir, config['raw_data_csv'])\n",
    "ltsf = \"{}/ltsf\".format(data_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e8a48d96",
   "metadata": {},
   "outputs": [],
   "source": [
    "default_args = read_default_args()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b449bd02",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['.DS_Store',\n",
       " 'instruments.json',\n",
       " '03_23.csv',\n",
       " '11_22.csv',\n",
       " '01_23.csv',\n",
       " '01_23.csv,03_23.csv',\n",
       " '09_22.csv',\n",
       " '07_22.csv']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.listdir(ltsf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "12e01f17",
   "metadata": {},
   "outputs": [],
   "source": [
    "args = {\n",
    "   'root_path': ltsf,\n",
    "   'checkpoints': '{}/checkpoints/'.format(data_dir),\n",
    "   'data_path': '03_23.csv',\n",
    "   'seq_len': 600,\n",
    "   'pred_len': 60,\n",
    "   'batch_size': 16,\n",
    "   'learning_rate': 0.05,\n",
    "   'train_only': False,\n",
    "   'train_epochs': 20,\n",
    "   'data_segment': [0, 1],\n",
    "   'model': 'nlinear_attention'\n",
    "}\n",
    "\n",
    "for key, value in args.items():\n",
    "    default_args[key] = value\n",
    "\n",
    "args = argparse.Namespace(**default_args)\n",
    "setting = 'mod_{}_sl{}_pl{}_ds_{}'.format(args.model, args.seq_len, args.pred_len, \n",
    "                                                 args.data_path.split('.')[0])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "9c3025c1",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1b74abcf",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Use CPU\n",
      "Total number of parameters is: 36068\n",
      "Data shape: (14250, 9)\n",
      "train 9316\n",
      "Data shape: (14250, 9)\n",
      "val 1366\n"
     ]
    }
   ],
   "source": [
    "exp = ExpMain(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "010059aa",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"<string>\", line 1, in <module>\n",
      "  File \"/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/multiprocessing/spawn.py\", line 116, in spawn_main\n",
      "    exitcode = _main(fd, parent_sentinel)\n",
      "  File \"/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/multiprocessing/spawn.py\", line 126, in _main\n",
      "    self = reduction.pickle.load(from_parent)\n",
      "_pickle.UnpicklingError: pickle data was truncated\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "mat1 and mat2 shapes cannot be multiplied (960x8 and 7x1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[12], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m exp\u001b[39m.\u001b[39;49mtrain(setting)\n",
      "File \u001b[0;32m~/Desktop/maestro/model-dev/expirement.py:126\u001b[0m, in \u001b[0;36mExpMain.train\u001b[0;34m(self, setting)\u001b[0m\n\u001b[1;32m    124\u001b[0m batch_x \u001b[39m=\u001b[39m batch_x\u001b[39m.\u001b[39mfloat()\u001b[39m.\u001b[39mto(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdevice)\n\u001b[1;32m    125\u001b[0m batch_y \u001b[39m=\u001b[39m batch_y\u001b[39m.\u001b[39mfloat()\u001b[39m.\u001b[39mto(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdevice)\n\u001b[0;32m--> 126\u001b[0m outputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmodel(batch_x)\n\u001b[1;32m    127\u001b[0m loss \u001b[39m=\u001b[39m criterion(outputs, batch_y)\n\u001b[1;32m    128\u001b[0m train_loss\u001b[39m.\u001b[39mappend(loss\u001b[39m.\u001b[39mitem())\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/torch/nn/modules/module.py:1051\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1047\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1048\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1049\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1050\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1051\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1052\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1053\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/Desktop/maestro/model-dev/models/nlinear_attention.py:42\u001b[0m, in \u001b[0;36mModel.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     40\u001b[0m     x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mLinear(x)  \u001b[39m# [Batch, Channel, Output length]\u001b[39;00m\n\u001b[1;32m     41\u001b[0m     x \u001b[39m=\u001b[39m x\u001b[39m.\u001b[39mpermute(\u001b[39m0\u001b[39m, \u001b[39m2\u001b[39m, \u001b[39m1\u001b[39m)  \u001b[39m# [Batch, Output length, Channel]\u001b[39;00m\n\u001b[0;32m---> 42\u001b[0m     x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mAttention(x)  \u001b[39m# [Batch, Output length, 1]\u001b[39;00m\n\u001b[1;32m     43\u001b[0m x \u001b[39m=\u001b[39m x \u001b[39m+\u001b[39m seq_last\n\u001b[1;32m     44\u001b[0m \u001b[39mreturn\u001b[39;00m x\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/torch/nn/modules/module.py:1051\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1047\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1048\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1049\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1050\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1051\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1052\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1053\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/torch/nn/modules/linear.py:96\u001b[0m, in \u001b[0;36mLinear.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     95\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m: Tensor) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tensor:\n\u001b[0;32m---> 96\u001b[0m     \u001b[39mreturn\u001b[39;00m F\u001b[39m.\u001b[39;49mlinear(\u001b[39minput\u001b[39;49m, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mweight, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbias)\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/torch/nn/functional.py:1847\u001b[0m, in \u001b[0;36mlinear\u001b[0;34m(input, weight, bias)\u001b[0m\n\u001b[1;32m   1845\u001b[0m \u001b[39mif\u001b[39;00m has_torch_function_variadic(\u001b[39minput\u001b[39m, weight):\n\u001b[1;32m   1846\u001b[0m     \u001b[39mreturn\u001b[39;00m handle_torch_function(linear, (\u001b[39minput\u001b[39m, weight), \u001b[39minput\u001b[39m, weight, bias\u001b[39m=\u001b[39mbias)\n\u001b[0;32m-> 1847\u001b[0m \u001b[39mreturn\u001b[39;00m torch\u001b[39m.\u001b[39;49m_C\u001b[39m.\u001b[39;49m_nn\u001b[39m.\u001b[39;49mlinear(\u001b[39minput\u001b[39;49m, weight, bias)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: mat1 and mat2 shapes cannot be multiplied (960x8 and 7x1)"
     ]
    }
   ],
   "source": [
    "exp.train(setting)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "ec72e8b5",
   "metadata": {},
   "source": [
    "## Multiple Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f273424",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "---------training for 03_23.csv file--------\n",
      "\n",
      "Use CPU\n",
      "Total number of parameters is: 7260\n",
      "train 9826\n",
      "val 1396\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████| 614/614 [00:59<00:00, 10.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 | time: 59.55973410606384\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1, Steps: 614 | Train Loss: 0.8700221 Vali Loss: 0.2118480\n",
      "Validation loss decreased (inf --> 0.211848).  Saving model ...\n",
      "Updating learning rate to 0.05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████| 614/614 [00:58<00:00, 10.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 2 | time: 58.891825914382935\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 2, Steps: 614 | Train Loss: 0.6312503 Vali Loss: 0.0500748\n",
      "Validation loss decreased (0.211848 --> 0.050075).  Saving model ...\n",
      "Updating learning rate to 0.025\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████| 614/614 [00:58<00:00, 10.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 3 | time: 58.894981145858765\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 3, Steps: 614 | Train Loss: 0.1540388 Vali Loss: 0.0287225\n",
      "Validation loss decreased (0.050075 --> 0.028722).  Saving model ...\n",
      "Updating learning rate to 0.0125\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████| 614/614 [00:58<00:00, 10.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 4 | time: 58.84666872024536\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 4, Steps: 614 | Train Loss: 0.0449502 Vali Loss: 0.0139745\n",
      "Validation loss decreased (0.028722 --> 0.013974).  Saving model ...\n",
      "Updating learning rate to 0.00625\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████| 614/614 [00:58<00:00, 10.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 5 | time: 58.83568787574768\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 5, Steps: 614 | Train Loss: 0.0276338 Vali Loss: 0.0128242\n",
      "Validation loss decreased (0.013974 --> 0.012824).  Saving model ...\n",
      "Updating learning rate to 0.003125\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████| 614/614 [00:58<00:00, 10.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 6 | time: 58.98821306228638\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 6, Steps: 614 | Train Loss: 0.0243896 Vali Loss: 0.0135479\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 0.0015625\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████| 614/614 [00:59<00:00, 10.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 7 | time: 59.65216374397278\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 7, Steps: 614 | Train Loss: 0.0227540 Vali Loss: 0.0129664\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 0.00078125\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████| 614/614 [01:01<00:00, 10.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 8 | time: 61.030369997024536\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 8, Steps: 614 | Train Loss: 0.0220520 Vali Loss: 0.0125300\n",
      "Validation loss decreased (0.012824 --> 0.012530).  Saving model ...\n",
      "Updating learning rate to 0.000390625\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████| 614/614 [00:59<00:00, 10.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 9 | time: 59.23407697677612\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 9, Steps: 614 | Train Loss: 0.0216585 Vali Loss: 0.0124471\n",
      "Validation loss decreased (0.012530 --> 0.012447).  Saving model ...\n",
      "Updating learning rate to 0.0001953125\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████| 614/614 [00:58<00:00, 10.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 10 | time: 58.76752996444702\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 10, Steps: 614 | Train Loss: 0.0214473 Vali Loss: 0.0125082\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 9.765625e-05\n",
      "\n",
      "---------training for 11_22.csv file--------\n",
      "\n",
      "Use CPU\n",
      "Total number of parameters is: 7260\n",
      "train 11401\n",
      "val 1621\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████| 712/712 [00:59<00:00, 12.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 | time: 59.283708810806274\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1, Steps: 712 | Train Loss: 0.2193825 Vali Loss: 14.1796932\n",
      "Validation loss decreased (inf --> 14.179693).  Saving model ...\n",
      "Updating learning rate to 0.05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████| 712/712 [00:59<00:00, 12.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 2 | time: 59.345792055130005\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 2, Steps: 712 | Train Loss: 0.0612713 Vali Loss: 12.0708904\n",
      "Validation loss decreased (14.179693 --> 12.070890).  Saving model ...\n",
      "Updating learning rate to 0.025\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████| 712/712 [01:00<00:00, 11.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 3 | time: 60.41328406333923\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 3, Steps: 712 | Train Loss: 0.0316069 Vali Loss: 2.4273098\n",
      "Validation loss decreased (12.070890 --> 2.427310).  Saving model ...\n",
      "Updating learning rate to 0.0125\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████| 712/712 [00:59<00:00, 12.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 4 | time: 59.35989284515381\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 4, Steps: 712 | Train Loss: 0.0243555 Vali Loss: 2.0003996\n",
      "Validation loss decreased (2.427310 --> 2.000400).  Saving model ...\n",
      "Updating learning rate to 0.00625\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████| 712/712 [00:59<00:00, 11.99it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 5 | time: 59.37443923950195\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 5, Steps: 712 | Train Loss: 0.0231443 Vali Loss: 1.9265890\n",
      "Validation loss decreased (2.000400 --> 1.926589).  Saving model ...\n",
      "Updating learning rate to 0.003125\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████| 712/712 [00:59<00:00, 11.99it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 6 | time: 59.391502141952515\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 6, Steps: 712 | Train Loss: 0.0228529 Vali Loss: 1.9480903\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 0.0015625\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████| 712/712 [00:59<00:00, 11.98it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 7 | time: 59.43736910820007\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 7, Steps: 712 | Train Loss: 0.0225232 Vali Loss: 1.9552898\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 0.00078125\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████| 712/712 [00:59<00:00, 12.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 8 | time: 59.25939893722534\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 8, Steps: 712 | Train Loss: 0.0223211 Vali Loss: 2.0052106\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "\n",
      "---------training for 01_23.csv file--------\n",
      "\n",
      "Use CPU\n",
      "Total number of parameters is: 7260\n",
      "train 10876\n",
      "val 1546\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████| 679/679 [00:58<00:00, 11.55it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 | time: 58.77874994277954\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1, Steps: 679 | Train Loss: 0.2230296 Vali Loss: 0.0228289\n",
      "Validation loss decreased (inf --> 0.022829).  Saving model ...\n",
      "Updating learning rate to 0.05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|▍                                                                                                             | 3/679 [00:07<26:59,  2.40s/it]\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Caught RuntimeError in DataLoader worker process 3.\nOriginal Traceback (most recent call last):\n  File \"/Users/shiva/Library/Python/3.9/lib/python/site-packages/torch/utils/data/_utils/worker.py\", line 287, in _worker_loop\n    data = fetcher.fetch(index)\n  File \"/Users/shiva/Library/Python/3.9/lib/python/site-packages/torch/utils/data/_utils/fetch.py\", line 47, in fetch\n    return self.collate_fn(data)\n  File \"/Users/shiva/Library/Python/3.9/lib/python/site-packages/torch/utils/data/_utils/collate.py\", line 84, in default_collate\n    return [default_collate(samples) for samples in transposed]\n  File \"/Users/shiva/Library/Python/3.9/lib/python/site-packages/torch/utils/data/_utils/collate.py\", line 84, in <listcomp>\n    return [default_collate(samples) for samples in transposed]\n  File \"/Users/shiva/Library/Python/3.9/lib/python/site-packages/torch/utils/data/_utils/collate.py\", line 64, in default_collate\n    return default_collate([torch.as_tensor(b) for b in batch])\n  File \"/Users/shiva/Library/Python/3.9/lib/python/site-packages/torch/utils/data/_utils/collate.py\", line 54, in default_collate\n    storage = elem.storage()._new_shared(numel)\n  File \"/Users/shiva/Library/Python/3.9/lib/python/site-packages/torch/storage.py\", line 155, in _new_shared\n    return cls._new_using_filename(size)\nRuntimeError: Resource temporarily unavailable at ../torch/lib/libshm/core.cpp:117\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[13], line 11\u001b[0m\n\u001b[1;32m      8\u001b[0m setting \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124msl\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m_pl\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m_ds_\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(args\u001b[38;5;241m.\u001b[39mseq_len, args\u001b[38;5;241m.\u001b[39mpred_len, args\u001b[38;5;241m.\u001b[39mdata_path\u001b[38;5;241m.\u001b[39msplit(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m'\u001b[39m)[\u001b[38;5;241m0\u001b[39m])\n\u001b[1;32m     10\u001b[0m exp \u001b[38;5;241m=\u001b[39m ExpMain(args)\n\u001b[0;32m---> 11\u001b[0m \u001b[43mexp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43msetting\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Desktop/maestro/model-dev/expirement.py:123\u001b[0m, in \u001b[0;36mExpMain.train\u001b[0;34m(self, setting)\u001b[0m\n\u001b[1;32m    121\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel\u001b[38;5;241m.\u001b[39mtrain()\n\u001b[1;32m    122\u001b[0m epoch_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[0;32m--> 123\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, (batch_x, batch_y) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(tqdm(train_loader)):\n\u001b[1;32m    124\u001b[0m     iter_count \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    125\u001b[0m     model_optim\u001b[38;5;241m.\u001b[39mzero_grad()\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/tqdm/std.py:1178\u001b[0m, in \u001b[0;36mtqdm.__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1175\u001b[0m time \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_time\n\u001b[1;32m   1177\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1178\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m obj \u001b[38;5;129;01min\u001b[39;00m iterable:\n\u001b[1;32m   1179\u001b[0m         \u001b[38;5;28;01myield\u001b[39;00m obj\n\u001b[1;32m   1180\u001b[0m         \u001b[38;5;66;03m# Update and possibly print the progressbar.\u001b[39;00m\n\u001b[1;32m   1181\u001b[0m         \u001b[38;5;66;03m# Note: does not call self.update(1) for speed optimisation.\u001b[39;00m\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/torch/utils/data/dataloader.py:521\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    519\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    520\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()\n\u001b[0;32m--> 521\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    522\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    523\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    524\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    525\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/torch/utils/data/dataloader.py:1203\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1201\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1202\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_task_info[idx]\n\u001b[0;32m-> 1203\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_process_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/torch/utils/data/dataloader.py:1229\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._process_data\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m   1227\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_try_put_index()\n\u001b[1;32m   1228\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data, ExceptionWrapper):\n\u001b[0;32m-> 1229\u001b[0m     \u001b[43mdata\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreraise\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1230\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m data\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/torch/_utils.py:425\u001b[0m, in \u001b[0;36mExceptionWrapper.reraise\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    421\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexc_type, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmessage\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m    422\u001b[0m     \u001b[38;5;66;03m# Some exceptions have first argument as non-str but explicitly\u001b[39;00m\n\u001b[1;32m    423\u001b[0m     \u001b[38;5;66;03m# have message field\u001b[39;00m\n\u001b[1;32m    424\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexc_type(message\u001b[38;5;241m=\u001b[39mmsg)\n\u001b[0;32m--> 425\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexc_type(msg)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Caught RuntimeError in DataLoader worker process 3.\nOriginal Traceback (most recent call last):\n  File \"/Users/shiva/Library/Python/3.9/lib/python/site-packages/torch/utils/data/_utils/worker.py\", line 287, in _worker_loop\n    data = fetcher.fetch(index)\n  File \"/Users/shiva/Library/Python/3.9/lib/python/site-packages/torch/utils/data/_utils/fetch.py\", line 47, in fetch\n    return self.collate_fn(data)\n  File \"/Users/shiva/Library/Python/3.9/lib/python/site-packages/torch/utils/data/_utils/collate.py\", line 84, in default_collate\n    return [default_collate(samples) for samples in transposed]\n  File \"/Users/shiva/Library/Python/3.9/lib/python/site-packages/torch/utils/data/_utils/collate.py\", line 84, in <listcomp>\n    return [default_collate(samples) for samples in transposed]\n  File \"/Users/shiva/Library/Python/3.9/lib/python/site-packages/torch/utils/data/_utils/collate.py\", line 64, in default_collate\n    return default_collate([torch.as_tensor(b) for b in batch])\n  File \"/Users/shiva/Library/Python/3.9/lib/python/site-packages/torch/utils/data/_utils/collate.py\", line 54, in default_collate\n    storage = elem.storage()._new_shared(numel)\n  File \"/Users/shiva/Library/Python/3.9/lib/python/site-packages/torch/storage.py\", line 155, in _new_shared\n    return cls._new_using_filename(size)\nRuntimeError: Resource temporarily unavailable at ../torch/lib/libshm/core.cpp:117\n"
     ]
    }
   ],
   "source": [
    "# for file in os.listdir(ltsf):\n",
    "    \n",
    "#     if not file.endswith('csv'):\n",
    "#         continue\n",
    "    \n",
    "#     print(\"\\n---------training for {} file--------\\n\".format(file))\n",
    "#     args.data_path = file\n",
    "#     setting = 'sl{}_pl{}_ds_{}'.format(args.seq_len, args.pred_len, args.data_path.split('.')[0])\n",
    "    \n",
    "#     exp = ExpMain(args)\n",
    "#     exp.train(setting)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "ff8f2882",
   "metadata": {},
   "source": [
    "## Dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "590c63dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data shape: (14250, 9)\n",
      "test 2791\n"
     ]
    }
   ],
   "source": [
    "data_iter, data_loader = data_provider(args, 'test', return_date=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "feba7bef",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
